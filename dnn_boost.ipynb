{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Somatic Mutation Identification with DNN-Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will demonstrate the somatic mutation identification of variants dataset from tumor-normal paired pancreatic cancer data. We will first use feature selection on the data using XGBoost and then train a deep neural netwook on the data with the selected features according to XGBoost (using Tensorflow).\n",
    "\n",
    "Note: \n",
    "Before running this tutorial, please install the following pacakages: pandas, matplotlib, Tensorflow, Sklearn, imblearn, and xgboost packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, average_precision_score, precision_recall_curve, plot_precision_recall_curve, plot_roc_curve\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_circles\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from tf.keras import layers\n",
    "from tf.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tf.keras.layers.experimental import preprocessing\n",
    "from tf.keras.regularizers import l2\n",
    "from tf.keras.models import Sequential, save_model, load_model\n",
    "from tf.keras.layers import Dense,Dropout,Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tf.keras.losses import categorical_crossentropy\n",
    "from tf.keras.optimizers import Adam\n",
    "from tf.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tf.keras.constraints import MaxNorm\n",
    "from tf.keras.models import model_from_json\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import EditedNearestNeighbours \n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from xgboost import plot_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset of variants from tumor-normal pancreatic cancer WES data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset from the training-data folder\n",
    "pancreatic_data = pd.read_csv('pancreatic_cancer_tumor-normal_data.csv',  header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Column Target matching Dictionary value\n",
    "map_labelMut = {'somatic_mutation': 1,\n",
    "                'germline': 0}\n",
    "\n",
    "pancreatic_data['target'] = pancreatic_data['label_mut'].map(map_labelMut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_copy = pancreatic_data[['ExAC_ALL','SIFT_score','Polyphen2_HDIV_score','Polyphen2_HVAR_score',\n",
    "                          'LRT_score','MutationTaster_score','MutationAssessor_score','FATHMM_score',\n",
    "                          'PROVEAN_score','VEST3_score','MetaSVM_score','MetaLR_score','M-CAP_score',\n",
    "                          'CADD_raw','CADD_phred','DANN_score','fathmm-MKL_coding_score','Eigen-raw',\n",
    "                          'Eigen-PC-raw','GenoCanyon_score','integrated_fitCons_score','GERP++_RS',\n",
    "                          'phyloP100way_vertebrate','phyloP20way_mammalian','phastCons100way_vertebrate',\n",
    "                          'phastCons20way_mammalian','SiPhy_29way_logOdds','gnomAD_exome_ALL','FS',\n",
    "                          'MQRankSum','QD','ReadPosRankSum','RPB','VAF','MQ','target']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_xgb = X_copy.columns[-1]\n",
    "X_xgb = X_copy.drop(label_xgb, axis = 1)\n",
    "Y_xgb = X_copy.drop(X_xgb, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "x_train_xgb, x_test_xgb, y_train_xgb, y_test_xgb = train_test_split(X_xgb, Y_xgb, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced Dataset Handling\n",
    "Because we have imbalanced datasets for the two classes, where the samples for \"Confirmed Somatic Variant\" dataset is much higher compare to the \"Germline\" class, we will create synthetic samples for the minority (\"Germline\") class. We used SMOTEENN for over-sampling (SMOTE) and noise cleaning (ENN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the parameters for SMOTE, ENN, and SMOTE-ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a SMOTE for oversampling\n",
    "smote = SMOTE(sampling_strategy=0.2, k_neighbors=7)\n",
    "\n",
    "# Create a ENN for undersampling\n",
    "enn = EditedNearestNeighbours(sampling_strategy='majority', n_neighbors=10)\n",
    "\n",
    "#Define the SMOTEENN resampling\n",
    "smote_enn = SMOTEENN(enn=enn, smote=smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_enn = smote_enn.fit(x_train_xgb, y_train_xgb)\n",
    "X_train_rsam_xgb, Y_train_rsam_xgb = smote_enn.fit_resample(x_train_xgb, y_train_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_ohe_train_xgb = pd.get_dummies(Y_train_rsam_xgb).astype(float).values\n",
    "Y_ohe_train_xgb = Y_ohe_train_xgb.ravel()\n",
    "X_ohe_train_xgb = X_train_rsam_xgb.astype(float).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_enn = smote_enn.fit(x_test_xgb, y_test_xgb)\n",
    "X_test_rsam_xgb, Y_test_rsam_xgb = smote_enn.fit_resample(x_test_xgb, y_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_ohe_test_xgb = pd.get_dummies(Y_test_rsam_xgb).astype(float).values\n",
    "Y_ohe_test_xgb = Y_ohe_test_xgb.ravel()\n",
    "X_ohe_test_xgb = X_test_rsam_xgb.astype(float).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data into DMatrices\n",
    "In order to use the native API for XGBoost, we will first need to build DMatrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train_rsam_xgb, label=Y_ohe_train_xgb)\n",
    "dtest = xgb.DMatrix(X_test_rsam_xgb, label=Y_ohe_test_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use mean absolute error (MAE) to evaluate the quality of our data train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth':3,\n",
    "    'min_child_weight': 1,\n",
    "    'eta': 0.1,\n",
    "    'subsample': 1.0,\n",
    "    'colsample_bytree': 0.1,\n",
    "    'objective':'binary:logistic',\n",
    "    'eval_metric': 'mae'\n",
    "}\n",
    "\n",
    "num_boost_round = 999\n",
    "\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = model.best_iteration + 1\n",
    "best_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the features based on the feature importance score, in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.gcf()\n",
    "fig, ax = plt.subplots(figsize=(30,30))\n",
    "xgb.plot_importance(best_model, max_num_features=100, height=0.5, ax=ax, importance_type='gain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the feature importance score according to 'gain' value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_important = best_model.get_score(importance_type='gain')\n",
    "keys = list(feature_important.keys())\n",
    "values = list(feature_important.values())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The dataframe data_xgb below is consisted of the features ranked according to its feature importance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframe\n",
    "data_xgb = pd.DataFrame(data=values, index=keys, columns=[\"score\"]).sort_values(by = \"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the 24 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_24=data_xgb[:24]\n",
    "print(feature_24.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Somatic Mutation Classification with DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the 24 features from the pancreatic tumor-normal data as the input for the DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_24=pancreatic_data[['ExAC_ALL', 'FS', 'DANN_score', 'MetaLR_score', 'MutationTaster_score',\n",
    "                           'gnomAD_exome_ALL', 'GenoCanyon_score', 'phastCons100way_vertebrate',\n",
    "                           'MetaSVM_score', 'CADD_raw', 'SIFT_score', 'VEST3_score',\n",
    "                           'MutationAssessor_score', 'phyloP20way_mammalian',\n",
    "                           'phyloP100way_vertebrate', 'CADD_phred', 'SiPhy_29way_logOdds', 'QD',\n",
    "                           'Polyphen2_HDIV_score', 'Eigen-raw', 'LRT_score',\n",
    "                           'phastCons20way_mammalian', 'M-CAP_score', 'ReadPosRankSum', 'label_mut']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = pancreatic_data[['ExAC_ALL', 'FS', 'MetaLR_score', 'DANN_score', 'gnomAD_exome_ALL',\n",
    "                               'GenoCanyon_score', 'MutationTaster_score', 'SIFT_score',\n",
    "                               'phastCons100way_vertebrate', 'MetaSVM_score', 'SiPhy_29way_logOdds',\n",
    "                               'phyloP20way_mammalian', 'VEST3_score', 'RPB', 'LRT_score',\n",
    "                               'M-CAP_score', 'CADD_raw', 'Eigen-raw', 'phyloP100way_vertebrate',\n",
    "                               'MutationAssessor_score', 'integrated_fitCons_score', 'QD',\n",
    "                               'ReadPosRankSum', 'PROVEAN_score', 'Polyphen2_HDIV_score', 'CADD_phred',\n",
    "                               'MQ', 'VAF', 'Polyphen2_HVAR_score', 'phastCons20way_mammalian',\n",
    "                               'GERP++_RS', 'MQRankSum', 'fathmm-MKL_coding_score', 'FATHMM_score',\n",
    "                               'Eigen-PC-raw','label_mut']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 29 Features for Breast Cancer Cell Line Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10738, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExAC_ALL</th>\n",
       "      <th>SIFT_score</th>\n",
       "      <th>Polyphen2_HDIV_score</th>\n",
       "      <th>Polyphen2_HVAR_score</th>\n",
       "      <th>LRT_score</th>\n",
       "      <th>MutationTaster_score</th>\n",
       "      <th>MutationAssessor_score</th>\n",
       "      <th>FATHMM_score</th>\n",
       "      <th>PROVEAN_score</th>\n",
       "      <th>VEST3_score</th>\n",
       "      <th>...</th>\n",
       "      <th>GenoCanyon_score</th>\n",
       "      <th>integrated_fitCons_score</th>\n",
       "      <th>GERP++_RS</th>\n",
       "      <th>phyloP100way_vertebrate</th>\n",
       "      <th>phyloP20way_mammalian</th>\n",
       "      <th>phastCons100way_vertebrate</th>\n",
       "      <th>phastCons20way_mammalian</th>\n",
       "      <th>SiPhy_29way_logOdds</th>\n",
       "      <th>gnomAD_exome_ALL</th>\n",
       "      <th>label_mut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chr1:7738411-7738411A&gt;T</th>\n",
       "      <td>0.009741</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.231000</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.420960</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.566925</td>\n",
       "      <td>0.142570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.647517</td>\n",
       "      <td>0.999269</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.139104</td>\n",
       "      <td>0.009533</td>\n",
       "      <td>somatic_mutation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:9931934-9931934T&gt;C</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.159195</td>\n",
       "      <td>0.647122</td>\n",
       "      <td>0.527146</td>\n",
       "      <td>0.070942</td>\n",
       "      <td>0.995585</td>\n",
       "      <td>0.592420</td>\n",
       "      <td>0.612064</td>\n",
       "      <td>0.603982</td>\n",
       "      <td>0.472573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894415</td>\n",
       "      <td>0.740215</td>\n",
       "      <td>0.856028</td>\n",
       "      <td>0.699113</td>\n",
       "      <td>0.928356</td>\n",
       "      <td>0.749829</td>\n",
       "      <td>0.755049</td>\n",
       "      <td>0.523358</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>somatic_mutation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:11082724-11082724G&gt;T</th>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.003707</td>\n",
       "      <td>0.987756</td>\n",
       "      <td>0.939537</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.683227</td>\n",
       "      <td>0.570391</td>\n",
       "      <td>0.464426</td>\n",
       "      <td>0.812273</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.841667</td>\n",
       "      <td>0.945317</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977472</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921000</td>\n",
       "      <td>0.589202</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>somatic_mutation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:11121988-11121988G&gt;T</th>\n",
       "      <td>0.013383</td>\n",
       "      <td>0.143047</td>\n",
       "      <td>0.618465</td>\n",
       "      <td>0.511401</td>\n",
       "      <td>0.075617</td>\n",
       "      <td>0.973139</td>\n",
       "      <td>0.553139</td>\n",
       "      <td>0.597409</td>\n",
       "      <td>0.603383</td>\n",
       "      <td>0.459190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823557</td>\n",
       "      <td>0.745147</td>\n",
       "      <td>0.862668</td>\n",
       "      <td>0.702512</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.766929</td>\n",
       "      <td>0.749596</td>\n",
       "      <td>0.527492</td>\n",
       "      <td>0.009305</td>\n",
       "      <td>somatic_mutation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:11167481-11167481G&gt;T</th>\n",
       "      <td>0.013383</td>\n",
       "      <td>0.143047</td>\n",
       "      <td>0.618465</td>\n",
       "      <td>0.511401</td>\n",
       "      <td>0.075617</td>\n",
       "      <td>0.973139</td>\n",
       "      <td>0.553139</td>\n",
       "      <td>0.597409</td>\n",
       "      <td>0.603383</td>\n",
       "      <td>0.459190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823557</td>\n",
       "      <td>0.745147</td>\n",
       "      <td>0.862668</td>\n",
       "      <td>0.702512</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.766929</td>\n",
       "      <td>0.749596</td>\n",
       "      <td>0.527492</td>\n",
       "      <td>0.009305</td>\n",
       "      <td>somatic_mutation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ExAC_ALL  SIFT_score  Polyphen2_HDIV_score  \\\n",
       "chr1:7738411-7738411A>T    0.009741    0.002000              0.775000   \n",
       "chr1:9931934-9931934T>C    0.000010    0.159195              0.647122   \n",
       "chr1:11082724-11082724G>T  0.000028    0.003707              0.987756   \n",
       "chr1:11121988-11121988G>T  0.013383    0.143047              0.618465   \n",
       "chr1:11167481-11167481G>T  0.013383    0.143047              0.618465   \n",
       "\n",
       "                           Polyphen2_HVAR_score  LRT_score  \\\n",
       "chr1:7738411-7738411A>T                0.231000   0.003012   \n",
       "chr1:9931934-9931934T>C                0.527146   0.070942   \n",
       "chr1:11082724-11082724G>T              0.939537   0.004016   \n",
       "chr1:11121988-11121988G>T              0.511401   0.075617   \n",
       "chr1:11167481-11167481G>T              0.511401   0.075617   \n",
       "\n",
       "                           MutationTaster_score  MutationAssessor_score  \\\n",
       "chr1:7738411-7738411A>T                0.655000                0.420960   \n",
       "chr1:9931934-9931934T>C                0.995585                0.592420   \n",
       "chr1:11082724-11082724G>T              1.000000                0.683227   \n",
       "chr1:11121988-11121988G>T              0.973139                0.553139   \n",
       "chr1:11167481-11167481G>T              0.973139                0.553139   \n",
       "\n",
       "                           FATHMM_score  PROVEAN_score  VEST3_score  ...  \\\n",
       "chr1:7738411-7738411A>T        0.672727       0.566925     0.142570  ...   \n",
       "chr1:9931934-9931934T>C        0.612064       0.603982     0.472573  ...   \n",
       "chr1:11082724-11082724G>T      0.570391       0.464426     0.812273  ...   \n",
       "chr1:11121988-11121988G>T      0.597409       0.603383     0.459190  ...   \n",
       "chr1:11167481-11167481G>T      0.597409       0.603383     0.459190  ...   \n",
       "\n",
       "                           GenoCanyon_score  integrated_fitCons_score  \\\n",
       "chr1:7738411-7738411A>T            0.015000                  0.732143   \n",
       "chr1:9931934-9931934T>C            0.894415                  0.740215   \n",
       "chr1:11082724-11082724G>T          1.000000                  0.841667   \n",
       "chr1:11121988-11121988G>T          0.823557                  0.745147   \n",
       "chr1:11167481-11167481G>T          0.823557                  0.745147   \n",
       "\n",
       "                           GERP++_RS  phyloP100way_vertebrate  \\\n",
       "chr1:7738411-7738411A>T     0.703140                 0.647517   \n",
       "chr1:9931934-9931934T>C     0.856028                 0.699113   \n",
       "chr1:11082724-11082724G>T   0.945317                 1.000000   \n",
       "chr1:11121988-11121988G>T   0.862668                 0.702512   \n",
       "chr1:11167481-11167481G>T   0.862668                 0.702512   \n",
       "\n",
       "                           phyloP20way_mammalian  phastCons100way_vertebrate  \\\n",
       "chr1:7738411-7738411A>T                 0.999269                    1.000000   \n",
       "chr1:9931934-9931934T>C                 0.928356                    0.749829   \n",
       "chr1:11082724-11082724G>T               0.977472                    1.000000   \n",
       "chr1:11121988-11121988G>T               0.922067                    0.766929   \n",
       "chr1:11167481-11167481G>T               0.922067                    0.766929   \n",
       "\n",
       "                           phastCons20way_mammalian  SiPhy_29way_logOdds  \\\n",
       "chr1:7738411-7738411A>T                    1.000000             0.139104   \n",
       "chr1:9931934-9931934T>C                    0.755049             0.523358   \n",
       "chr1:11082724-11082724G>T                  0.921000             0.589202   \n",
       "chr1:11121988-11121988G>T                  0.749596             0.527492   \n",
       "chr1:11167481-11167481G>T                  0.749596             0.527492   \n",
       "\n",
       "                           gnomAD_exome_ALL         label_mut  \n",
       "chr1:7738411-7738411A>T            0.009533  somatic_mutation  \n",
       "chr1:9931934-9931934T>C            0.000000  somatic_mutation  \n",
       "chr1:11082724-11082724G>T          0.000022  somatic_mutation  \n",
       "chr1:11121988-11121988G>T          0.009305  somatic_mutation  \n",
       "chr1:11167481-11167481G>T          0.009305  somatic_mutation  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_29=pancreatic_data[['ExAC_ALL','SIFT_score','Polyphen2_HDIV_score','Polyphen2_HVAR_score',\n",
    "                 'LRT_score','MutationTaster_score','MutationAssessor_score','FATHMM_score',\n",
    "                 'PROVEAN_score','VEST3_score','MetaSVM_score','MetaLR_score','M-CAP_score',\n",
    "                 'CADD_raw','CADD_phred','DANN_score','fathmm-MKL_coding_score','Eigen-raw',\n",
    "                 'Eigen-PC-raw','GenoCanyon_score','integrated_fitCons_score','GERP++_RS',\n",
    "                 'phyloP100way_vertebrate','phyloP20way_mammalian','phastCons100way_vertebrate',\n",
    "                 'phastCons20way_mammalian','SiPhy_29way_logOdds','gnomAD_exome_ALL',\n",
    "                 'MQ', 'label_mut']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate features and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the dataset with the full features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label = full_dataset.columns[-1]\n",
    "#X = full_dataset.drop(label, axis = 1)\n",
    "#Y = full_dataset.drop(X, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the dataset with the 29 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label = feature_29.columns[-1]\n",
    "#X = feature_29.drop(label, axis = 1)\n",
    "#Y = feature_29.drop(X, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the dataset with the 24 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = feature_24.columns[-1]\n",
    "X = feature_24.drop(label, axis = 1)\n",
    "Y = feature_24.drop(X, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('One-hot encoding labels.')\n",
    "Y_ohe= pd.get_dummies(Y).astype(float).values\n",
    "# Get training data as numpy array\n",
    "# because of non overlap\n",
    "X_ohe = X.astype(float).values\n",
    "print('Training shape is: ', X_ohe.shape)\n",
    "print('Labels encoded shape is: ', Y_ohe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the train and test data for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_ohe, Y_ohe, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the SMOTE-ENN to the training data of DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_enn = smote_enn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN Model Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the F1-metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the parameters of scheduling and callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-3,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(name_weights, patience_lr):\n",
    "    mcp_save = ModelCheckpoint(name_weights, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=patience_lr, verbose=1, min_delta=1e-4, mode='min')\n",
    "    return [mcp_save, reduce_lr_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_metric(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters\n",
    "batch_size=100\n",
    "loss_function = categorical_crossentropy\n",
    "num_classes = 2\n",
    "no_epochs=100\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "verbosity = 1\n",
    "num_folds = 10\n",
    "input_shape = x_train.shape[1]\n",
    "\n",
    "# Define the performance metrics for the model\n",
    "METRICS = ['accuracy',\n",
    "           tf.keras.metrics.AUC(name='auc'),\n",
    "           tf.keras.metrics.Precision(name='precision'),\n",
    "           tf.keras.metrics.Recall(name='recall'),\n",
    "           tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "           tf.keras.metrics.TruePositives(name='tp'),\n",
    "           tf.keras.metrics.FalsePositives(name='fp'),\n",
    "           tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "           tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "           f1_metric\n",
    "          ]\n",
    "\n",
    "# Create Model\n",
    "def make_model(metrics=METRICS, output_bias=None):\n",
    "    model = Sequential([\n",
    "        layers.Dense(64, input_dim=input_shape, activation='relu', kernel_initializer='normal', kernel_regularizer=l2(0.01), kernel_constraint=MaxNorm(5)),\n",
    "        layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        layers.Dense(num_classes, kernel_initializer='normal', activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        loss=loss_function,\n",
    "        optimizer=optimizer,\n",
    "        metrics=METRICS)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define per-fold training score containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_training_fold = []\n",
    "fp_training_fold = []\n",
    "tn_training_fold = []\n",
    "fn_training_fold = []\n",
    "loss_training_fold = []\n",
    "auc_training_fold = []\n",
    "acc_training_fold = []\n",
    "precision_training_fold = []\n",
    "recall_training_fold = []\n",
    "training_f1_scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define per-fold validation score containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_per_fold = []\n",
    "fp_per_fold = []\n",
    "tn_per_fold = []\n",
    "fn_per_fold = []\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "auc_per_fold = []\n",
    "precision_per_fold = []\n",
    "prc_per_fold = []\n",
    "recall_per_fold = []\n",
    "val_f1scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "start = time.time()\n",
    "for train, test in kfold.split(x_train, y_train):\n",
    "    \n",
    "    X_train_rsam, Y_train_rsam = smote_enn.fit_resample(x_train[train], y_train[train])\n",
    "    Y_train_rsam = np.eye(2)[Y_train_rsam.flatten()]\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    # Fit data to model\n",
    "    name_weights = \"final_model_fold\" + str(fold_no) + \"_weights.h5\"\n",
    "    callbacks = get_callbacks(name_weights = name_weights, patience_lr=10)\n",
    "    history = model.fit(X_train_rsam, Y_train_rsam,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=no_epochs,\n",
    "                        verbose=verbosity,\n",
    "                        validation_data = (x_train[test], y_train[test]),\n",
    "                        callbacks=callbacks)\n",
    "    end = time.time()\n",
    "    \n",
    "    loss_training_fold.append(history.history['loss'])\n",
    "    auc_training_fold.append(history.history['auc'] * 100)\n",
    "    tp_training_fold.append(history.history['tp'])\n",
    "    fp_training_fold.append(history.history['fp'])\n",
    "    tn_training_fold.append(history.history['tn'])\n",
    "    fn_training_fold.append(history.history['fn'])\n",
    "    acc_training_fold.append(history.history['accuracy'] * 100)\n",
    "    precision_training_fold.append(history.history['precision'] * 100)\n",
    "    recall_training_fold.append(history.history['recall'] * 100)\n",
    "    training_f1_scores.append(history.history['f1_metric'] * 100 )\n",
    "    \n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(x_train[test], y_train[test], verbose=0)\n",
    "    print(f'Validation score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%; {model.metrics_names[2]} of {scores[2]*100}%; {model.metrics_names[3]} of {scores[3] * 100}%; {model.metrics_names[4]} of {scores[4] * 100}%; {model.metrics_names[10]} of {scores[10] * 100}%')\n",
    "    loss_per_fold.append(scores[0])\n",
    "    acc_per_fold.append((scores[1] * 100))\n",
    "    auc_per_fold.append((scores[2] * 100))\n",
    "    precision_per_fold.append((scores[3] * 100))\n",
    "    recall_per_fold.append((scores[4] * 100))\n",
    "    prc_per_fold.append(scores[5])\n",
    "    tp_per_fold.append(scores[6])\n",
    "    fp_per_fold.append(scores[7])\n",
    "    tn_per_fold.append(scores[8])\n",
    "    fn_per_fold.append(scores[9])\n",
    "    val_f1scores.append(round((scores[10] * 100), 2))\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "\n",
    "# == Display average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Validation score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {(loss_per_fold[i])} - Accuracy: {acc_per_fold[i]}% - AUC: {auc_per_fold[i]}% - Precision: {precision_per_fold[i]}% - Recall: {recall_per_fold[i]}% - F1-score: {val_f1scores[i]}%')\n",
    "print(\"Execution time for training is: %f\"%(float(end)- float(start)))\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average training scores for all folds:')\n",
    "print(f'> Loss: {np.mean(loss_training_fold)}')\n",
    "print(f'> Accuracy: {(np.mean(acc_training_fold )* 100)} (+- {np.std(acc_training_fold)})')\n",
    "print(f'> AUC: {(np.mean(auc_training_fold)* 100)} (+- {np.std(auc_training_fold)})')\n",
    "print(f'> Precision: {(np.mean(precision_training_fold) * 100)} (+- {np.std(precision_training_fold)})')\n",
    "print(f'> Recall: {(np.mean(recall_training_fold) * 100)} (+- {np.std(recall_training_fold)})')\n",
    "print(f'> F1-score: {(np.mean(training_f1_scores) * 100)} (+- {np.std(training_f1_scores)})')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average validation scores for all folds:')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> AUC: {np.mean(auc_per_fold)} (+- {np.std(auc_per_fold)})')\n",
    "print(f'> Precision: {np.mean(precision_per_fold)} (+- {np.std(precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(recall_per_fold)} (+- {np.std(recall_per_fold)})')\n",
    "print(f'> F1-score: {np.mean(val_f1scores)} (+- {np.std(val_f1scores)})')\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "# Serialize Model to JSON\n",
    "json_model = model.to_json()\n",
    "with open('dnn_boost_pancreatic_24features.json', 'w') as json_file:\n",
    "    json_file.write(json_model)\n",
    "    \n",
    "# Serialize weights to HDF5\n",
    "model.save_weights('dnn_boost_pancreatic_24features')\n",
    "print(\"Saved model to disk\")\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "print('Succesfully trained model!')\n",
    "\n",
    "# For breast cancer cell line classification using 29 features\n",
    "# Serialize Model to JSON\n",
    "#json_model = model.to_json()\n",
    "#with open('dnn_boost_pancreatic_29features.json', 'w') as json_file:\n",
    "#    json_file.write(json_model)\n",
    "    \n",
    "# Serialize weights to HDF5\n",
    "#model.save_weights('dnn_boost_pancreatic_29features')\n",
    "#print(\"Saved model to disk\")\n",
    "#print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "#print('Succesfully trained model!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of the testing data with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample the testing data\n",
    "smote_enn=smote_enn.fit(x_test, y_test)\n",
    "x_test_resamp, y_test_resamp = smote_enn.fit_resample(x_test, y_test)\n",
    "y_test_resamp = np.eye(2)[y_test_resamp.flatten()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the prediction of the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_cat = model.predict(x_test_resamp, batch_size=100, verbose=verbosity).round()\n",
    "accuracy_final = accuracy_score(y_test_resamp, y_test_pred_cat)\n",
    "recall_final = recall_score(y_test_resamp, y_test_pred_cat, average='weighted')\n",
    "precision_final = precision_score(y_test_resamp, y_test_pred_cat, average='weighted')\n",
    "#calculate F1 score\n",
    "f1_final = f1_score(y_test_resamp, y_test_pred_cat, average='weighted')\n",
    "print('Accuracy of prediction model:')\n",
    "print(f'> Prediction accuracy: {(accuracy_final * 100)} ')\n",
    "print('Precision of prediction model:')\n",
    "print(f'> Precision: {(precision_final * 100)} ')\n",
    "print('Recall of prediction model:')\n",
    "print(f'> Recall: {(recall_final * 100)} ')\n",
    "print('F1-score of prediction model:')\n",
    "print(f'> F1: {(f1_final * 100)} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of the tumor-only dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset from the tumor-only_data folder\n",
    "tumor_only_data = pd.read_csv('pancreatic_cancer_tumor-only_data.csv',  header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_labelMut = {'somatic_mutation': 1,\n",
    "                'germline': 0}\n",
    "\n",
    "tumor_only_data['target'] = tumor_only_data['label_mut'].map(map_labelMut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the same 24 features according to the XGBoost feature importance test from the tumor-normal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_only_feature24=tumor_only_data[['ExAC_ALL', 'FS', 'MetaLR_score', 'DANN_score', 'gnomAD_exome_ALL',\n",
    "       'GenoCanyon_score', 'MutationTaster_score', 'SIFT_score',\n",
    "       'phastCons100way_vertebrate', 'MetaSVM_score', 'SiPhy_29way_logOdds',\n",
    "       'phyloP20way_mammalian', 'VEST3_score', 'RPB', 'LRT_score',\n",
    "       'M-CAP_score', 'CADD_raw', 'Eigen-raw', 'phyloP100way_vertebrate',\n",
    "       'MutationAssessor_score', 'integrated_fitCons_score', 'QD',\n",
    "       'ReadPosRankSum', 'PROVEAN_score','target']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Column Target matching Dictionary value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = tumor_only_feature24.columns[-1]\n",
    "X = tumor_only_feature24.drop(label, axis = 1)\n",
    "Y = tumor_only_feature24.drop(X, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ohe = X.astype(float).values\n",
    "Y_ohe = Y['target'].values\n",
    "Y_true = np.eye(2)[Y_ohe.flatten()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the tumor-only dataset using the trained model from the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull in model from output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('dnn_boost_pancreatic_24features.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model_24 = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights into new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_24.load_weights('dnn_boost_pancreatic_24features')\n",
    "print(\"Loaded model from disk\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify the tumor-only dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_24 = loaded_model_24.predict(X_ohe, batch_size=100, verbose=1).round()\n",
    "accuracy_final = accuracy_score(Y_true, y_pred_24)\n",
    "recall_final = recall_score(Y_true, y_pred_24, average='weighted')\n",
    "precision_final = precision_score(Y_true, y_pred_24, average='weighted')\n",
    "#calculate F1 score\n",
    "f1_final = f1_score(Y_true, y_pred_24, average='weighted')\n",
    "print('Accuracy of prediction model:')\n",
    "print(f'> Prediction accuracy: {(accuracy_final * 100)} ')\n",
    "print('Precision of prediction model:')\n",
    "print(f'> Precision: {(precision_final * 100)} ')\n",
    "print('Recall of prediction model:')\n",
    "print(f'> Recall: {(recall_final * 100)} ')\n",
    "print('F1-score of prediction model:')\n",
    "print(f'> F1: {(f1_final * 100)} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of the breast cancer cell line data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset from the breast_cancer_data folder\n",
    "\n",
    "#breast_mut_data = pd.read_csv('HCC1143_breast_cancer.csv',  header=0, index_col=0)\n",
    "breast_mut_data = pd.read_csv('HCC1954_breast_cancer.csv',  header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Column Target matching Dictionary value\n",
    "map_labelMut = {'somatic_mutation': 1 ,\n",
    "                'germline': 0}\n",
    "#map_labelMut = {'somatic_mutation': 1}\n",
    "\n",
    "breast_mut_data['target'] = breast_mut_data['label_mut'].map(map_labelMut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the same 29 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_feature29=breast_mut_data[['ExAC_ALL','SIFT_score','Polyphen2_HDIV_score','Polyphen2_HVAR_score',\n",
    "                 'LRT_score','MutationTaster_score','MutationAssessor_score','FATHMM_score',\n",
    "                 'PROVEAN_score','VEST3_score','MetaSVM_score','MetaLR_score','M-CAP_score',\n",
    "                 'CADD_raw','CADD_phred','DANN_score','fathmm-MKL_coding_score','Eigen-raw',\n",
    "                 'Eigen-PC-raw','GenoCanyon_score','integrated_fitCons_score','GERP++_RS',\n",
    "                 'phyloP100way_vertebrate','phyloP20way_mammalian','phastCons100way_vertebrate',\n",
    "                 'phastCons20way_mammalian','SiPhy_29way_logOdds','gnomAD_exome_ALL',\n",
    "                 'MQ','target']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Column Target matching Dictionary value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = breast_feature29.columns[-1]\n",
    "X = breast_feature29.drop(label, axis = 1)\n",
    "Y = breast_feature29.drop(X, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ohe = X.astype(float).values\n",
    "Y_ohe = Y['target'].values\n",
    "Y_true = np.eye(2)[Y_ohe.flatten()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the breast cancer cell line dataset using the trained model from the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull in model from output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('dnn_boost_pancreatic_29features.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model_29 = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights into new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_29.load_weights('dnn_boost_pancreatic_29features')\n",
    "print(\"Loaded model from disk\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify the tumor-only dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_29 = loaded_model_29.predict(X_ohe, batch_size=100, verbose=1).round()\n",
    "accuracy_final = accuracy_score(Y_true, y_pred_29)\n",
    "recall_final = recall_score(Y_true, y_pred_29, average='weighted')\n",
    "precision_final = precision_score(Y_true, y_pred_29, average='weighted')\n",
    "#calculate F1 score\n",
    "f1_final = f1_score(Y_true, y_pred_29, average='weighted')\n",
    "print('Accuracy of prediction model:')\n",
    "print(f'> Prediction accuracy: {(accuracy_final * 100)} ')\n",
    "print('Precision of prediction model:')\n",
    "print(f'> Precision: {(precision_final * 100)} ')\n",
    "print('Recall of prediction model:')\n",
    "print(f'> Recall: {(recall_final * 100)} ')\n",
    "print('F1-score of prediction model:')\n",
    "print(f'> F1: {(f1_final * 100)} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo, we showed the workflow of DNN-Boost, consisted of feature selection with XGBoost and classification with four-layers DNN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
